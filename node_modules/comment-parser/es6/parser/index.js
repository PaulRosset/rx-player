import sourceParser from './source-parser';
import blockParser from './block-parser';
import specParser, { tagTokenizer, nameTokenizer, typeTokenizer, descriptionTokenizer, } from './spec-parser';
import getSpacer from './spacer';
import { splitLines } from '../util';
export default function getParser(_a) {
    var _b = _a === void 0 ? {} : _a, _c = _b.startLine, startLine = _c === void 0 ? 0 : _c, _d = _b.fence, fence = _d === void 0 ? '```' : _d, _e = _b.spacing, spacing = _e === void 0 ? 'compact' : _e, _f = _b.tokenizers, tokenizers = _f === void 0 ? [
        tagTokenizer(),
        typeTokenizer(),
        nameTokenizer(),
        descriptionTokenizer(getSpacer(spacing)),
    ] : _f;
    if (startLine < 0 || startLine % 1 > 0)
        throw new Error('Invalid startLine');
    var parseSource = sourceParser({ startLine: startLine });
    var parseBlock = blockParser({ fence: fence });
    var parseSpec = specParser({ tokenizers: tokenizers });
    var join = getSpacer(spacing);
    var notEmpty = function (line) {
        return line.tokens.description.trim() != '';
    };
    return function (source) {
        var blocks = [];
        for (var _i = 0, _a = splitLines(source); _i < _a.length; _i++) {
            var line = _a[_i];
            var lines = parseSource(line);
            if (lines === null)
                continue;
            if (lines.find(notEmpty) === undefined)
                continue;
            var sections = parseBlock(lines);
            var specs = sections.slice(1).map(parseSpec);
            blocks.push({
                description: join(sections[0]),
                tags: specs,
                source: lines,
                problems: specs.reduce(function (acc, spec) { return acc.concat(spec.problems); }, []),
            });
        }
        return blocks;
    };
}
